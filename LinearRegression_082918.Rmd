---
title: "Data Exploration Linear Reg"
author: "Wynne Moss"
date: "August 28, 2018"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## The data

Data is from previously published paper (Moss et al. 2016) using stable isotopes to understand cougar diet in wildland urban interfaces.
Data struture:
1) individual ID for each cougar collared
2) X_15N isotope signature for nitrogen
3) X_13C isotope signature for carbon
4) age class as categorical
5) sex
6) age class in months
7) median housing density within home range

```{r}
coug <- read.csv("cougarisotopedata.csv")
str(coug)
colnames(coug)[2:3] <- c("N15", "C13")
coug <- coug[complete.cases(coug),]
coug$logHD <- log(coug$HousingDensity+1)
```
# Explore variables
```{r}
hist(coug$N15)
hist(coug$C13)
hist(coug$HousingDensity)
hist(log(coug$HousingDensity + 1))
```

# Fitting model with OLS

```{r, OLSmodel}
Nlm <- lm(N15~logHD, coug); summary(Nlm)
x<- seq(min(coug$logHD), max(coug$logHD), length.out = 1000)
?predict
predictios <- data.frame(predict.lm(Nlm, newdata = data.frame("logHD"=x), interval = "confidence"))
{plot(N15~logHD, coug, type = "n")
polygon(c(x, rev(x)), c(predictios$lwr, rev(predictios$upr)), border=NA, col="lightgray")
abline(Nlm)
points(N15~logHD, coug, pch =16, col = "dodgerblue")}

```

# Optim using SSQ not log-likelihood
```{r}
# make a likelihood function
ssq.func <- function(params, x, y_obs){
  pred <- params[1] + params[2]*x
  ssq.sum <- sum((pred-y_obs)^2)
  return(ssq.sum)
}
# test it
ssq.func(params = c(2, 0.1), x = coug$logHD, y_obs = coug$N15)

# optimize it iwth initial guesses slope = 0.1, int = 0.1

lm1<- optim(c(0.1, 0.1), ssq.func,  x = coug$logHD, y_obs = coug$N15, method = "BFGS")
lm1$par
Nlm$coefficients
```

# Fitting model with log-likelihood
```{r}
coug$logHD <- log(coug$HousingDensity+1)
design_Full <- model.matrix(~logHD, data = coug)
design_Full
likeFunc <- function(params, X, y){
    k <- ncol(X)
    b <- params[1:k]
    sigma <- params[k+1]
    yhat <- X %*% b
    ll <- sum(dnorm(y, yhat, sigma, log=T))
    return(-ll)
}
# coug$HDCent <- with(coug, logHD-mean(logHD))
# design_X <- model.matrix(~HDCent, coug)
fit_FullN <- optim(c(7.5,1,1), likeFunc, X=design_Full, y=coug$N15, method = "BFGS", hessian=T)
fit_FullN$par
SEs <- sqrt(diag(solve(fit_FullN$hessian)))
SEs

tval <- qt(0.025, nrow(coug)-3)
lower <- fit_FullN$par + tval*SEs[]
upper <- fit_FullN$par - tval*SEs[]
lower
upper
confint(Nlm)
params <- fit_FullN$par
Sigma <- solve(fit_FullN$hessian)
# CONFIDENCE INTERVALS

library(mvtnorm)

xPred = with(coug, seq(min(logHD), max(logHD), len=100))
post_draw <- function(){
  post_draw <- rmvnorm(1, params, Sigma)
  yhat <- post_draw[1]+post_draw[2]*xPred
  return(yhat)
}
post_preds <- replicate(1000, post_draw())
lower <- apply(post_preds, 1, function(x) quantile(x, 0.025))
upper <- apply(post_preds, 1, function(x) quantile(x, 0.975))

{plot(N15 ~ logHD, data=coug, pch=16)
polygon(c(xPred, rev(xPred)), c(lower, rev(upper)),
border=NA, col="lightgray")
yhat = params[1] + params[2]*xPred
lines(xPred, yhat, col="red", lw=2)
points(N15~logHD, coug, pch=16)}

```

